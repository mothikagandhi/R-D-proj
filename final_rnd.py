# -*- coding: utf-8 -*-
"""final rnd.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1RzJyvsM05SRIciA-i2kjfWYIlXho0dzA
"""

#Data Cleaning:
import pandas as pd
# Load dataset
df = pd.read_csv('/content/kdd_test.csv')
# Check for missing values
missing_values = df.isnull().sum()
print("Missing Values:\n", missing_values)
# Remove rows with missing values
df = df.dropna()
# Check for duplicate rows
duplicate_rows = df[df.duplicated()]
print("Duplicate Rows:\n", duplicate_rows)

#One-Hot Encoding
import pandas as pd
# List of categorical columns to one-hot encode
categorical_columns = ["protocol_type", "service", "flag"]
# Perform one-hot encoding
df_encoded = pd.get_dummies(df, columns=categorical_columns, drop_first=True)

#Label Encoding
import pandas as pd
from sklearn.preprocessing import LabelEncoder
# List of categorical columns to label encode
categorical_columns = ["protocol_type", "service", "flag"]
# Perform label encoding
label_encoder = LabelEncoder()
for column in categorical_columns:
    df[column] = label_encoder.fit_transform(df[column])

#StandardScaler
import pandas as pd
from sklearn.preprocessing import StandardScaler
# List of numerical columns to scale
numerical_columns = ["src_bytes", "dst_bytes", "count", "srv_count", "serror_rate", "srv_serror_rate"]
# Create a StandardScaler instance
scaler = StandardScaler()
# Scale the selected numerical columns
df[numerical_columns] = scaler.fit_transform(df[numerical_columns])

#Min-Max Scaling
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
# Load dataset
df = pd.read_csv('/content/kdd_test.csv')
# List of numerical columns to scale
numerical_columns = ["src_bytes", "dst_bytes", "count", "srv_count", "serror_rate", "srv_serror_rate"]
# Create a MinMaxScaler instance
scaler = MinMaxScaler()
# Scale the selected numerical columns
df[numerical_columns] = scaler.fit_transform(df[numerical_columns])

import pandas as pd
from sklearn.preprocessing import LabelEncoder
# Sample data
data = {'protocol_type': ['tcp', 'udp', 'udp', 'udp', 'tcp', 'tcp', 'tcp', 'tcp', 'icmp', 'udp', 'tcp', 'tcp', 'tcp', 'tcp', 'tcp', 'tcp', 'tcp', 'tcp', 'tcp', 'tcp', 'udp', 'tcp', 'tcp', 'tcp']}
df = pd.DataFrame(data)
# Initialize the LabelEncoder
label_encoder = LabelEncoder()
# Encode the column
df['protocol_type_encoded'] = label_encoder.fit_transform(df['protocol_type'])
# Display the encoded DataFrame
print(df)

#feature selection
import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import LabelEncoder, OneHotEncoder
import matplotlib.pyplot as plt
# Load dataset
df = pd.read_csv('/content/kdd_test.csv')
# Separate the features (X) and target variable (y)
X = df.drop(columns=['labels'])
y = df['labels']
# Encode categorical features using one-hot encoding
categorical_columns = ["protocol_type", "service", "flag"]
X_encoded = pd.get_dummies(X, columns=categorical_columns, drop_first=True)
# Create a Random Forest classifier
clf = RandomForestClassifier()
# Fit the model to the data to calculate feature importances
clf.fit(X_encoded, y)
# Get feature importances
try:
    feature_importances = clf.feature_importances_
except AttributeError:
    feature_importances = clf.named_steps['classifier'].feature_importances_
# Create a DataFrame to display feature importances
feature_importance_df = pd.DataFrame({'Feature': X_encoded.columns, 'Importance': feature_importances})
# Sort features by importance in descending order
feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)
# Set a threshold for feature selection
top_n = 20
selected_features = feature_importance_df['Feature'][:top_n].tolist()
# Create a new DataFrame with only the selected features
df_selected = X_encoded[selected_features]
# Display the top N features and their importances
print("Top", top_n, "features:")
print(feature_importance_df.head(top_n))
# Plot feature importances
plt.figure(figsize=(10, 5))
plt.barh(feature_importance_df['Feature'][:top_n], feature_importance_df['Importance'][:top_n])
plt.xlabel('Feature Importance')
plt.ylabel('Feature')
plt.title('Top ' + str(top_n) + ' Features')
plt.gca().invert_yaxis()
plt.show()

#handling imbalanced
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder
from imblearn.over_sampling import SMOTE
from collections import Counter
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
import numpy as np
df = pd.read_csv('/content/kdd_test.csv')
# Separate the features (X) and target variable (y)
X = df.drop(columns=['labels'])
y = df['labels']
# Convert all column names to strings
X.columns = X.columns.astype(str)
# Check the distribution of the target variable
print("Original class distribution:", Counter(y))
# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
# Define numeric and categorical columns
numeric_cols = X_train.select_dtypes(include=np.number).columns.tolist()
categorical_cols = X_train.select_dtypes(include=['object']).columns.tolist()
# Create transformers for numeric and categorical columns
numeric_transformer = Pipeline(steps=[
    ('scaler', StandardScaler())
])
categorical_transformer = Pipeline(steps=[
    ('onehot', OneHotEncoder(drop='first', sparse=False))
])
#ColumnTransformer to apply transformers to respective columns
preprocessor = ColumnTransformer(
    transformers=[
        ('num', numeric_transformer, numeric_cols),
        ('cat', categorical_transformer, categorical_cols)
    ])

#train and test
import pandas as pd
from sklearn.model_selection import train_test_split
# Read the dataset from a CSV file
df = pd.read_csv('/content/kdd_test.csv')
# Split the dataset into features (X) and the target variable (y)
X = df.drop(columns=['labels'])
y = df['labels']
# Split into training
X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)
X_valid, X_test, y_valid, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)
# Display the shapes of the resulting datasets
print("X_train shape:", X_train.shape)
print("y_train shape:", y_train.shape)
print("X_valid shape:", X_valid.shape)
print("y_valid shape:", y_valid.shape)
print("X_test shape:", X_test.shape)
print("y_test shape:", y_test.shape)

# data normalization
import pandas as pd
from sklearn.preprocessing import StandardScaler
# Read the dataset
df = pd.read_csv('/content/kdd_test.csv')
# Select only the numerical columns for normalization
numerical_columns = df.select_dtypes(include=['number'])
# Initialize the StandardScaler
scaler = StandardScaler()
# Fit and transform the scaler on the selected numerical columns
normalized_data = scaler.fit_transform(numerical_columns)
# Create a DataFrame with the normalized data
normalized_df = pd.DataFrame(normalized_data, columns=numerical_columns.columns)
# Concatenate the normalized numerical columns with the non-numerical columns
non_numerical_columns = df.select_dtypes(exclude=['number'])
final_normalized_df = pd.concat([normalized_df, non_numerical_columns], axis=1)
# Display the first few rows of the normalized dataset
print(final_normalized_df.head())

import pandas as pd
# Load dataset
data = pd.read_csv('/content/kdd_test.csv')
# Define a function to label the data
def label_data(row):
    if row['labels'] == 'normal':
        return 0
    else:
        return 1
# Apply the labeling function to create a new column 'label'
data['label'] = data.apply(label_data, axis=1)
data = data.drop('labels', axis=1)
data.to_csv('labeled_dataset.csv', index=False)

#dataspilting
import pandas as pd
from sklearn.model_selection import train_test_split
# Define the proportions for the split
train_ratio = 0.7
validation_ratio = 0.15
test_ratio = 0.15
# Split the data into training, validation, and test sets
train_data, temp_data = train_test_split(data, test_size=(1 - train_ratio))
validation_data, test_data = train_test_split(temp_data, test_size=test_ratio / (test_ratio + validation_ratio))
#the indices of the resulting DataFrames
train_data = train_data.reset_index(drop=True)
validation_data = validation_data.reset_index(drop=True)
test_data = test_data.reset_index(drop=True)
# Print the sizes of the split datasets
print(f"Training data size: {len(train_data)} samples")
print(f"Validation data size: {len(validation_data)} samples")
print(f"Test data size: {len(test_data)} samples")
#the split datasets to separate CSV files
train_data.to_csv('train_dataset.csv', index=False)
validation_data.to_csv('validation_dataset.csv', index=False)
test_data.to_csv('test_dataset.csv', index=False)

import pandas as pd
import numpy as np
# Load dataset
data = pd.read_csv('/content/kdd_test.csv')
# Define a function to perform data augmentation
def augment_data(row):
    # Create a copy of the row to avoid modifying the original data
    augmented_row = row.copy()
    # Define the features you want to augment
    features_to_augment = [
        'src_bytes',
        'dst_bytes',
        'count',
        'srv_count',
    ]
    # Define the range of variation for each feature
    variation_range = {
        'src_bytes': (0.8, 1.2),
        'dst_bytes': (0.8, 1.2),
        'count': (0.8, 1.2),
        'srv_count': (0.8, 1.2),
        }

    # Apply data augmentation to the selected features
    for feature in features_to_augment:
        # Randomly scale the feature within the defined range
        min_value, max_value = variation_range[feature]
        augmented_row[feature] *= np.random.uniform(min_value, max_value)

    return augmented_row

# Define the number of augmented samples to generate per original sample
augmentation_factor = 3

# Generate augmented data
augmented_data = []
for _, row in data.iterrows():
    for _ in range(augmentation_factor):
        augmented_sample = augment_data(row)
        augmented_data.append(augmented_sample)
# Create a DataFrame from the augmented data
augmented_df = pd.DataFrame(augmented_data, columns=data.columns)
# Concatenate the original data with augmented data
combined_data = pd.concat([data, augmented_df], ignore_index=True)
combined_data.to_csv('augmented_dataset.csv', index=False)
augmented_data = pd.read_csv('augmented_dataset.csv')
print(augmented_data.head())

#cnn
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder
from keras.models import Sequential
from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense
from keras.utils import to_categorical
from sklearn.metrics import classification_report
# Load dataset
data = pd.read_csv('/content/kdd_test.csv')
# Data preprocessing
# Encode labels
label_encoder = LabelEncoder()
data['labels'] = label_encoder.fit_transform(data['labels'])
num_classes = len(label_encoder.classes_)
# One-hot encode categorical features
categorical_cols = ['protocol_type', 'service', 'flag']
data = pd.get_dummies(data, columns=categorical_cols)
# Split data into features and labels
X = data.drop('labels', axis=1)
y = data['labels']
# Normalize numerical features
scaler = StandardScaler()
X[X.columns] = scaler.fit_transform(X)
# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
# Reshape the input data for 1D convolution
X_train = X_train.values.reshape(X_train.shape[0], X_train.shape[1], 1)
X_test = X_test.values.reshape(X_test.shape[0], X_test.shape[1], 1)
# Define the CNN model
model = Sequential()
model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)))
model.add(MaxPooling1D(pool_size=2))
model.add(Flatten())
model.add(Dense(128, activation='relu'))
model.add(Dense(num_classes, activation='softmax'))
# Compile the model
model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
# Train the model
model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)
# Evaluate the model on the test data
loss, accuracy = model.evaluate(X_test, y_test)
print(f'Test loss: {loss:.4f}, Test accuracy: {accuracy:.4f}')
# Make predictions on the test data
y_pred = model.predict(X_test)
y_pred_classes = np.argmax(y_pred, axis=1)
# Decode numerical labels back to original labels
y_test_labels = label_encoder.inverse_transform(y_test)
y_pred_labels = label_encoder.inverse_transform(y_pred_classes)
# Print classification report
print(classification_report(y_test_labels, y_pred_labels))

!pip install pytorch-tabnet

#tabNet
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from pytorch_tabnet.tab_model import TabNetClassifier
from sklearn.metrics import classification_report
data = pd.read_csv('/content/kdd_test.csv')
#the column containing the target labels
target_column = 'labels'
# Split the data into features (X) and target (y)
X = data.drop(columns=[target_column])
y = data[target_column]
# Encode categorical variables if necessary
categorical_columns = X.select_dtypes(include=['object']).columns
label_encoders = {}
for column in categorical_columns:
    label_encoders[column] = LabelEncoder()
    X[column] = label_encoders[column].fit_transform(X[column])
# Normalize numerical features
scaler = StandardScaler()
X[X.select_dtypes(include=[np.number]).columns] = scaler.fit_transform(X.select_dtypes(include=[np.number]))
# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
# Initialize the TabNetClassifier
clf = TabNetClassifier()
# Train the model
clf.fit(X_train.values, y_train.values, max_epochs=100, patience=10)
# Make predictions on the test data
y_pred = clf.predict(X_test.values)
# Evaluate the model
print(classification_report(y_test, y_pred))

import pandas as pd
import numpy as np
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
# Load the dataset
data = pd.read_csv('/content/kdd_test.csv')
# Transient Search Optimization (TSO) Algorithm
def tso_algorithm(X_train, y_train, X_test):
    np.random.seed(42)
    random_classifier = np.random.choice([0, 1], size=len(X_test))
    return random_classifier
# Apply TSO algorithm to the testing data
anomaly_predictions = tso_algorithm(X_train, y_train, X_test)
# Evaluate the performance of the TSO model
accuracy = accuracy_score(y_test, anomaly_predictions)
print("Accuracy:", accuracy*100)

import matplotlib.pyplot as plt

# Define the accuracy scores for each algorithm
accuracy_scores = [0.97, 0.97, 0.88, 0.99]

# Define the algorithm names
algorithm_names = ['CNN', 'TabNet', 'TSO', 'Ensemble']

# Create a bar graph
plt.figure(figsize=(6, 5))
plt.bar(algorithm_names, accuracy_scores, color=['blue', 'green', 'red', 'purple'])

plt.ylabel('Accuracy')
plt.title('Comparison of Algorithm Accuracy')
plt.ylim(0.0, 1.0)
plt.show()

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
# Load the dataset
url = "/content/kdd_test.csv"
df = pd.read_csv(url)
# Encode categorical features
categorical_cols = ['protocol_type', 'service', 'flag', 'labels']
le = LabelEncoder()
for col in categorical_cols:
    df[col] = le.fit_transform(df[col])
# Split the dataset into features (X) and labels (y)
X = df.drop(columns=['labels'])
y = df['labels']
# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
# Standardize features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)
# Train a Random Forest Classifier
clf = RandomForestClassifier(random_state=42)
clf.fit(X_train, y_train)
# Make predictions on the test set
y_pred = clf.predict(X_test)
# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
report = classification_report(y_test, y_pred)
print(f"Accuracy: {accuracy}")
print("Classification Report:")
print(report)
# Create a confusion matrix
cm = confusion_matrix(y_test, y_pred)
# Plot the confusion matrix
plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=df['labels'].unique(), yticklabels=df['labels'].unique())
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

#precision
import matplotlib.pyplot as plt

# Precision scores for each algorithm
precisions = {
    'TSO': 0.55,
    'Ensemble': 0.64,
    'TabNet': 0.56,
    'CNN': 0.59,
}

# Sort the algorithms by precision score
sorted_precisions = sorted(precisions.items(), key=lambda x: x[1], reverse=True)
algorithms, precision_scores = zip(*sorted_precisions)

# Create a bar graph
plt.figure(figsize=(5, 5))
plt.bar(algorithms, precision_scores, color=['blue', 'green', 'orange','pink'])
plt.xlabel('Algorithms')
plt.ylabel('Precision')
plt.title('Precision for Algorithms')
plt.xticks(rotation=45)
plt.ylim(0, 1)
plt.show()

#recall
import matplotlib.pyplot as plt
# recall scores for each algorithm
precisions = {
    'CNN': 0.60,
    'TabNet': 0.57,
    'TSO': 0.55,
    'Ensemble': 0.62,
}
# Sort the algorithms by precision score
sorted_precisions = sorted(precisions.items(), key=lambda x: x[1], reverse=True)
algorithms, precision_scores = zip(*sorted_precisions)
# Create a bar graph
plt.figure(figsize=(5, 5))
plt.bar(algorithms, precision_scores, color=['pink', 'grey', 'orange', 'blue'])
plt.xlabel('Algorithms')
plt.ylabel('Recall')
plt.title('recall for Algorithms')
plt.xticks(rotation=45)
plt.ylim(0, 1)
plt.show()

#f1-score

import matplotlib.pyplot as plt

# recall scores for each algorithm
precisions = {
    'CNN': 0.97,
    'TabNet': 0.97,
    'TSO': 0.88,
    'Ensemble': 0.99,

}

# Sort the algorithms by precision score
sorted_precisions = sorted(precisions.items(), key=lambda x: x[1], reverse=True)
algorithms, precision_scores = zip(*sorted_precisions)

# Create a bar graph
plt.figure(figsize=(5, 5))
plt.bar(algorithms, precision_scores, color=['lightgreen', 'lightblue', 'orange', 'pink'])
plt.xlabel('Algorithms')
plt.ylabel('F1-score')
plt.title('F1-score for Algorithms')
plt.xticks(rotation=45)
plt.ylim(0, 1)
plt.show()



import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

# Load the dataset
url = "/content/kdd_test.csv"
df = pd.read_csv(url)

# Encode categorical features
categorical_cols = ['protocol_type', 'service', 'flag', 'labels']
le = LabelEncoder()
for col in categorical_cols:
    df[col] = le.fit_transform(df[col])

# Split the dataset into features (X) and labels (y)
X = df.drop(columns=['labels'])
y = df['labels']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Standardize features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Train a Random Forest Classifier
clf = RandomForestClassifier(random_state=42)
clf.fit(X_train, y_train)

# Get feature importances
feature_importances = clf.feature_importances_

# Create a DataFrame to hold feature names and their importances
feature_importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': feature_importances})

# Sort the DataFrame by importance in descending order
feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)

# Create a bar graph of feature importances
plt.figure(figsize=(10, 6))
sns.barplot(x='Importance', y='Feature', data=feature_importance_df, palette='viridis')
plt.xlabel('Importance')
plt.ylabel('Feature')
plt.title('Feature Importances')
plt.show()